{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf\n",
    "\n",
    "import ollama\n",
    "import os\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull granite3.2\n",
    "!ollama pull granite3.2-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_text_files(keyword: str) -> str:\n",
    "  \n",
    "  directory = os.listdir(\"./files/\")\n",
    "  for fname in directory:\n",
    "    \n",
    "    # look through all the files in our directory that aren't hidden files\n",
    "    if os.path.isfile(\"./files/\" + fname) and not fname.startswith('.'):\n",
    "\n",
    "        if(fname.endswith(\".pdf\")):\n",
    "           \n",
    "           document_text = \"\"\n",
    "           doc = pymupdf.open(\"./files/\" + fname)\n",
    "\n",
    "           for page in doc: # iterate the document pages\n",
    "               document_text += page.get_text() # get plain text (is in UTF-8)\n",
    "               \n",
    "           doc.close()\n",
    "\n",
    "           prompt = \"Respond only 'yes' or 'no', do not add any additional information. Is the following text about \" + keyword + \"? \" + document_text \n",
    "\n",
    "           res = ollama.chat(\n",
    "                model=\"granite3.2:8b\",\n",
    "                messages=[{'role': 'user', 'content': prompt}]\n",
    "            )\n",
    "\n",
    "           if 'Yes' in res['message']['content']:\n",
    "                return \"./files/\" + fname\n",
    "\n",
    "        elif(fname.endswith(\".txt\")):\n",
    "\n",
    "            f = open(\"./files/\" + fname, 'r')\n",
    "            file_content = f.read()\n",
    "            \n",
    "            prompt = \"Respond only 'yes' or 'no', do not add any additional information. Is the following text about \" + keyword + \"? \" + file_content \n",
    "\n",
    "            res = ollama.chat(\n",
    "                model=\"granite3.2:8b\",\n",
    "                messages=[{'role': 'user', 'content': prompt}]\n",
    "            )\n",
    "           \n",
    "            if 'Yes' in res['message']['content']:\n",
    "                f.close()\n",
    "                return \"./files/\" + fname\n",
    "\n",
    "  return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_image_files(keyword:str) -> str:\n",
    "\n",
    "    directory = os.listdir(\"./files/\")\n",
    "    image_file_types = (\"jpg\", \"png\", \"jpeg\")\n",
    "\n",
    "    for fname in directory:\n",
    "\n",
    "        if os.path.isfile(\"./files/\" + fname) and not fname.startswith('.') and fname.endswith(image_file_types):\n",
    "            res = ollama.chat(\n",
    "                model=\"granite3.2-vision\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': 'Describe this image in short sentences. Use simple phrases first and then describe it more fully.',\n",
    "                        'images': [\"./files/\" + fname]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if keyword in res['message']['content']:\n",
    "                return \"./files/\" + fname\n",
    "    \n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "  'Search inside text files':search_text_files,\n",
    "  'Search inside image files':search_image_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools don't need to be defined as an object but this helps pass the correct parameters\n",
    "# to the tool call itself by giving the model a prompt of how the tool is to be used\n",
    "ollama_tools=[\n",
    "     {\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'Search inside text files',\n",
    "        'description': 'This tool searches in PDF or plaintext or text files in the local file system for descriptions or mentions of the keyword.',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'keyword': {\n",
    "              'type': 'string',\n",
    "              'description': 'Generate one keyword from the user request to search for in text files',\n",
    "            },\n",
    "          },\n",
    "          'required': ['keyword'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "    {\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'Search inside image files',\n",
    "        'description': 'This tool searches for photos or image files in the local file system for the keyword.',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'keyword': {\n",
    "              'type': 'string',\n",
    "              'description': 'Generate one keyword from the user request to search for in image files',\n",
    "            },\n",
    "          },\n",
    "          'required': ['keyword'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ollama is not currently running, start it\n",
    "import subprocess\n",
    "subprocess.Popen([\"ollama\",\"serve\"], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866361ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "user_input = input(\"What would you like to search for?\")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c87e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'user', 'content':user_input}]\n",
    "\n",
    "response: ollama.ChatResponse = ollama.chat(\n",
    "   \n",
    "  # set which model we're using\n",
    "  'granite3.2:8b',\n",
    "\n",
    "  # use the message from the user\n",
    "  messages=messages,\n",
    "\n",
    "  tools=ollama_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a place holder that to use to see whether the tools return anything \n",
    "output = []\n",
    "\n",
    "if response.message.tool_calls:\n",
    "  \n",
    "  # There may be multiple tool calls in the response\n",
    "  for tool_call in response.message.tool_calls:\n",
    "\n",
    "    # Ensure the function is available, and then call it\n",
    "    if function_to_call := available_functions.get(tool_call.function.name):\n",
    "      print('Calling tool: ', tool_call.function.name, ' \\n with arguments: ', tool_call.function.arguments)\n",
    "      tool_res = function_to_call(**tool_call.function.arguments)\n",
    "\n",
    "      print(\" Tool response is \" + str(tool_res))\n",
    "\n",
    "      if(str(tool_res) != \"None\"):\n",
    "        output.append(str(tool_res))\n",
    "        print(tool_call.function.name, ' has output: ', output)\n",
    "    else:\n",
    "      print('Could not find ', tool_call.function.name)\n",
    "\n",
    "  # Now chat with the model using the tool call results\n",
    "  # Add the function response to messages for the model to use\n",
    "  messages.append(response.message)\n",
    "\n",
    "  prompt = '''\n",
    "    If the tool output contains one or more file names, then give the user only the filename found. Do not add additional details. \n",
    "    If the tool output is empty ask the user to try again. Here is the tool output: \n",
    "  '''\n",
    "\n",
    "  messages.append({'role': 'tool', 'content': prompt + \" \" + \", \".join(str(x) for x in output)})\n",
    "  \n",
    "  # Get a response from model with function outputs\n",
    "  final_response = ollama.chat('granite3.2:8b', messages=messages)\n",
    "  print('Final response:', final_response.message.content)\n",
    "\n",
    "else:\n",
    "\n",
    "  # the model wasn't able to pick the correct tool from the prompt\n",
    "  print('No tool calls returned from model')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
